# Reverse Engineering Memories

This section studies **reverse engineering user memories from queries** and proposes a system to **mitigate sensitive information exposure** while preserving the original user intent.

We develop:
1. A system that alerts users about the extent of information that can be stored in memory if every user query is considered.
2. A solution that recommends **privacy-preserving query reformulations**, preventing sensitive information from being exposed in memories while retaining similar intent to the original query.

The dataset includes:
- Ground-truth memories  
- Original user queries  
- Rephrased (privacy-preserving) queries generated by the GPT-4o model  

---

## Problem Formulation

Given:
- A **user query**
- The corresponding **ground-truth memory**
- A **privacy-preserving rephrased query**

We aim to train and evaluate models that can:
- Extract or imitate memory information from queries
- Generate reformulated queries that reduce sensitive information leakage

---

## Methods

We provide **two approaches** to solve this problem:

### 1. Supervised Fine-Tuning (SFT)
Train an open-source model using paired data:
- `(query, memory)`
- `(query, rephrased_query)`

### 2. In-Context Learning (ICL)
Use an open-source model with in-context examples consisting of:
- `(query, memory)`
- `(query, rephrased_query)`

No parameter updates are required for this method.

---

## Repository Structure

```text
.
├── util_public
│   ├── inference
│   ├── training
│   │   ├── config
│   ├── models.json
│   ├── chat_template
│
├── train_imitating_memory_extractor
│   ├── main.py
│   ├── construct_dataset_custome.py
│   └── _submit_in_batch.sh
│
├── inference_imitating_memory_extractor
│   ├── main.py
│   ├── config.yaml
│   ├── generation.py
│   ├── construct_prompt.py
│   └── get_examples.py
│
└── result_analysis
    └── preprocess.py
    └── annotate_memory.py
    └── attribution_gpt.py
    └── get_first_query.py
    └── get_human_eval.py
    └── gpt_response.py
```

---

## Training

### Main Training Entry Point
The main training loop is implemented in:

```text
/train_imitating_memory_extractor/main.py
```

You can modify training hyperparameters and configurations directly in this file.

### Custom Dataset Handling
Customized dataset construction is handled by:

```text
/train_imitating_memory_extractor/construct_dataset_custome.py
```

### Distributed Training (Slurm)
To submit training jobs to a Slurm cluster, use:

```text
/train_imitating_memory_extractor/_submit_in_batch.sh
```

### DeepSpeed Configuration
DeepSpeed configuration files are provided under:

```text
/util_public/training/config
```

---

## Inference

### Configuration
All inference-related configurations can be modified in:

```text
/inference_imitating_memory_extractor/config.yaml
```

### Main Inference Pipeline
The main evaluation and inference pipeline is implemented in:

```text
/inference_imitating_memory_extractor/main.py
```

### Generation Settings
Detailed generation logic and decoding strategies are implemented in:

```text
/inference_imitating_memory_extractor/generation.py
```

### Prompt Construction
Prompt generation for both SFT and ICL is implemented in:

```text
/inference_imitating_memory_extractor/construct_prompt.py
```

### In-Context Example Selection
The logic for retrieving ICL examples is implemented in:

```text
/inference_imitating_memory_extractor/get_examples.py
```

---

## Models

Model paths are stored and managed in:

```text
/util_public/models.json
```

Each model also has a corresponding chat template under:

```text
/util_public/chat_template/
```

---

## Result Analysis

To analyze the outputs generated by the imitating memory extractors, we provide comprehensive evaluation utilities.

### Metrics and Preprocessing
All preprocessing and metric computation functions (for generated memories and rephrased queries against ground truth) are implemented in:

```text
/result_analysis/preprocess.py
```

### Human and GPT Annotations
The repository also includes code demonstrating:
- How human annotation samples are selected
- How GPT-based annotations are generated and evaluated

---
