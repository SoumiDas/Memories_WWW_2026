chat_template: .../util_public/chat_templates/qwen2.5.jinja
epochs: 10
gradient_accumulation_steps: 8
learning_rate: 5.0e-05
lr_scheduler_type: cosine
model_name: qwen2.5-32b-instruct
output_dir: .../self_trained
per_device_eval_batch_size: 1
per_device_train_batch_size: 1
save_label: 0
seed: 42
train_data_name: train
train_ratio: 0.6
wandb_run_name: qwen2.5-32b-instruct_query-memory_0.6_1
warmup_steps: 5
model_path_map: .../util_public/models.json
