{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38994d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "gpt_4o_annotations_path = \"../dummy_data/tom_annotated_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de687416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations_from_folder(path):\n",
    "    \"\"\"\n",
    "    Load all annotation JSON files with file/folder metadata into a dataframe.\n",
    "    Adds all annotation keys (at top-level) as columns in the dataframe.\n",
    "    Assumes: `path` contains user-level subfolders, then conversation subfolders.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "\n",
    "    for user_folder in os.listdir(path):  # user_id folders\n",
    "        user_path = os.path.join(path, user_folder)\n",
    "        if os.path.isdir(user_path):\n",
    "            for conv_folder in os.listdir(user_path):  # conversation folders\n",
    "                conv_path = os.path.join(user_path, conv_folder)\n",
    "                if os.path.isdir(conv_path):\n",
    "                    for file_name in os.listdir(conv_path):\n",
    "                        file_path = os.path.join(conv_path, file_name)\n",
    "                        if os.path.isfile(file_path):\n",
    "                            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                                file_content = f.read()\n",
    "                            result = json.loads(file_content)\n",
    "                            row = {\n",
    "                                \"user_id\": user_folder,\n",
    "                                \"conversation_id\": conv_folder,\n",
    "                                \"memory_id\": file_name.replace(\".json\", \"\"),\n",
    "                                \"file_name\": file_name,\n",
    "                                \"file_path\": file_path,\n",
    "                                \"raw_content\": result\n",
    "                            }\n",
    "                            # Add all keys from annotation JSON at the top level to the row\n",
    "                            if isinstance(result, dict):\n",
    "                                for k, v in result.items():\n",
    "                                    # Avoid overwriting our metadata columns\n",
    "                                    if k not in row:\n",
    "                                        row[k] = v\n",
    "                            records.append(row)\n",
    "    df = pd.DataFrame(records)\n",
    "    return df\n",
    "\n",
    "# Load annotations\n",
    "df_gpt_4o = load_annotations_from_folder(gpt_4o_annotations_path)\n",
    "df_gpt_4o.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a339cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load human annotations\n",
    "\n",
    "annot_1 = pd.read_csv(\"../dummy_data/annotator1_tom_annotations.csv\")\n",
    "annot_2 = pd.read_csv(\"../dummy_data/annotator2_tom_annotations.csv\", delimiter=\";\")\n",
    "\n",
    "assert len(annot_1) == len(annot_2)\n",
    "\n",
    "def normalize_columns(df):\n",
    "    # Normalize column names to lowercase for matching\n",
    "    rename_map = {}\n",
    "    for col in df.columns:\n",
    "        if col == \"ToM\":\n",
    "            rename_map[col] = \"ToM\"\n",
    "        elif col.lower() in [\"percepts\", \"percept\"]:\n",
    "            rename_map[col] = \"percept\"\n",
    "        else:\n",
    "            rename_map[col] = col.lower()\n",
    "    df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "normalize_columns(annot_1)\n",
    "normalize_columns(annot_2)\n",
    "\n",
    "annot_1_aligned = annot_1.set_index(\"memory_id\")\n",
    "annot_2_aligned = annot_2.set_index(\"memory_id\")\n",
    "\n",
    "# Check that all memory_id values from annotators are in gpt_4o_old_df\n",
    "missing_ids_1 = set(annot_1[\"memory_id\"]) - set(df_gpt_4o[\"memory_id\"])\n",
    "missing_ids_2 = set(annot_2[\"memory_id\"]) - set(df_gpt_4o[\"memory_id\"])\n",
    "if missing_ids_1 or missing_ids_2:\n",
    "    print(f\"Memory IDs in annotators not found in model annotations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855704ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def compute_agreement(df1, df2, col):\n",
    "    \"\"\"Compute agreement between two annotators.\"\"\"\n",
    "    return np.mean(df1[col].values == df2[col].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f07b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTER-ANNOTATOR AGREEMENT\n",
    "CATEGORIES = [\n",
    "    \"ToM\", \"emotion\", \"desire\", \"intention\", \"percept\", \"belief\"\n",
    "]\n",
    "\n",
    "agreement = []\n",
    "\n",
    "for col in CATEGORIES:\n",
    "    # Percentage agreement\n",
    "    agree = compute_agreement(annot_1_aligned, annot_2_aligned, col)\n",
    "    agreement.append(agree)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Category': CATEGORIES,\n",
    "    'Agreement': agreement,\n",
    "})\n",
    "\n",
    "print(\"INTER-ANNOTATOR AGREEMENT\")\n",
    "display(results_df.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93911a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL-ANNOTATOR AGREEMENT\n",
    "\n",
    "def compute_consensus_two(a1, a2):\n",
    "    \"\"\"\n",
    "    Compute consensus for each row among two annotators.\n",
    "    Consensus is defined as the value if both annotators agree, otherwise np.nan.\n",
    "    Returns an array with consensus values (0 or 1) or np.nan where there is no consensus.\n",
    "    \"\"\"\n",
    "    consensus = np.where(a1 == a2, a1, np.nan)\n",
    "    return consensus\n",
    "\n",
    "\n",
    "# Build consensus DataFrame\n",
    "human_consensus = annot_1[[\"memory_id\"]].copy() if \"memory_id\" in annot_1.columns else annot_1.copy()\n",
    "for col in CATEGORIES:\n",
    "    consensus_col = compute_consensus_two(annot_1[col].values, annot_2[col].values)\n",
    "    human_consensus[col] = consensus_col\n",
    "\n",
    "def compute_agreement_consensus_vs_model(consensus, amodel):\n",
    "    \"\"\"Compute agreement (mean of ==) between consensus and model, only for consensus items.\"\"\"\n",
    "    mask = ~np.isnan(consensus)\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.nan\n",
    "    return np.mean(consensus[mask] == amodel[mask])\n",
    "\n",
    "agreement = []\n",
    "for col in CATEGORIES:\n",
    "\n",
    "    # Align both DataFrames on memory_id before comparing\n",
    "    human_consensus_aligned = human_consensus.set_index(\"memory_id\")\n",
    "    df_gpt_4o_aligned = df_gpt_4o.set_index(\"memory_id\")\n",
    "\n",
    "    # Only compare on shared memory_ids\n",
    "    shared_memory_ids = human_consensus_aligned.index.intersection(df_gpt_4o_aligned.index)\n",
    "    human_consensus_aligned = human_consensus_aligned.loc[shared_memory_ids]\n",
    "    df_gpt_4o_aligned = df_gpt_4o_aligned.loc[shared_memory_ids]\n",
    "    \n",
    "    agreement.append(compute_agreement_consensus_vs_model(human_consensus_aligned[col].values, df_gpt_4o_aligned[col].values))\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Category': CATEGORIES,\n",
    "    'Agreement': agreement,\n",
    "})\n",
    "\n",
    "print(\"MODEL-ANNOTATOR AGREEMENT\")\n",
    "display(results_df.round(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
